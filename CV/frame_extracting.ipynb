{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Extract Frames from Selected Film\n",
    "\n",
    "Extract frames and get thumbnail images for checking accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from IPython.display import display, Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "TIME_INTERVAL = 5.0 # second(s)\n",
    "\n",
    "VIDEO_PATH = '../../Temp/我们村里的年轻人（续集）.mp4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Running with OpenCV version \" + cv2.__version__)\n",
    "\n",
    "VIDEO_NAME = VIDEO_PATH.split('/')[-1]\n",
    "if VIDEO_NAME.endswith('.mp4'):\n",
    "\tVIDEO_NAME = VIDEO_NAME[:-4]\n",
    "print(\"Video name: \" + VIDEO_NAME)\n",
    "\n",
    "def extractImages(pathIn, pathOut, export_thumbnails=False, thumbnail_path=\"./thumbnails/cache/\", thumbnail_interval=1, thumbnail_scale=0.25):\n",
    "\t\"\"\"\n",
    "\tParameters\n",
    "\t----------\n",
    "\texport_thumbnails: boolean, whether to export thumbnails\n",
    "\tthumbnail_path: string, path (relative) to save thumbnails\n",
    "\tthumbnail_interval: int, after how many frames to save a thumbnail\n",
    "\t\"\"\"\n",
    "    \n",
    "\tcount = 0\n",
    "\tvidcap = cv2.VideoCapture(pathIn)\n",
    "\tsuccess,image = vidcap.read()\n",
    "\tsuccess = True\n",
    "\ttotal_secs = vidcap.get(cv2.CAP_PROP_FRAME_COUNT) / vidcap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "\tp_bar = tqdm(total=total_secs, desc='Extracting frames')\n",
    "\t#p_bar = FloatProgress(min=0, max=total_secs, description='Extracting frames')\n",
    "\t#display(p_bar)\n",
    "\n",
    "\twhile success:\n",
    "\t\tpos = count*TIME_INTERVAL # seconds\n",
    "\t\tif pos > total_secs:\n",
    "\t\t\tbreak\n",
    "\t\t\n",
    "\t\tvidcap.set(cv2.CAP_PROP_POS_MSEC, pos * 1000)\n",
    "\t\tp_bar.update(TIME_INTERVAL)\n",
    "\t\tsuccess,image = vidcap.read()\n",
    "\t\t#p_bar.value = pos\n",
    "\t\t\n",
    "\t\ttarget = pathOut + f\"/{VIDEO_NAME}-{count}.jpg\"\n",
    "\t\t#print('sec {} of {} ({})'.format(pos, total_secs, target))\n",
    "\t\tcv2.imwrite(filename=target, img=image)\n",
    "\t\tcount = count + 1\n",
    "\n",
    "\t\tif export_thumbnails and count % thumbnail_interval == 0:\n",
    "\t\t\t# save a thumbnail with 1/4 size of the original image\n",
    "\t\t\tthumb = cv2.resize(image, (0, 0), fx=thumbnail_scale, fy=thumbnail_scale)\n",
    "\t\t\tthumbnail_target = thumbnail_path + f\"{VIDEO_NAME}-thumb{count}.jpg\"\n",
    "\t\t\tcv2.imwrite(filename=thumbnail_target, img=thumb)\n",
    "        \n",
    "\tvidcap.release()\n",
    "\tprint(f'\\n{count} frames extracted with the time interval of {TIME_INTERVAL} secs.\\nLast frame example:')\n",
    "\tdisplay(Image(target)) # show the last frame as an example\n",
    "\n",
    "extractImages(VIDEO_PATH, \"./Temp\", export_thumbnails=False, thumbnail_interval=30, thumbnail_scale=0.25)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Person Identification\n",
    "\n",
    "Add ONNX format YOLO v7 models to folder \"CV/YOLO\" to use it in person identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import onnxruntime as ort\n",
    "import glob\n",
    "\n",
    "w = \"YOLO/yolov7-w6.onnx\"\n",
    "cuda = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "providers = ['CoreMLExecutionProvider', 'CPUExecutionProvider'] if cuda else ['CPUExecutionProvider']\n",
    "print(providers)\n",
    "session = ort.InferenceSession(w, providers=providers)\n",
    "\n",
    "def letterbox(im, new_shape=(640, 640), color=(114, 114, 114), auto=True, scaleup=True, stride=32):\n",
    "    # Resize and pad image while meeting stride-multiple constraints\n",
    "    shape = im.shape[:2]  # current shape [height, width]\n",
    "    if isinstance(new_shape, int):\n",
    "        new_shape = (new_shape, new_shape)\n",
    "\n",
    "    # Scale ratio (new / old)\n",
    "    r = min(new_shape[0] / shape[0], new_shape[1] / shape[1])\n",
    "    if not scaleup:  # only scale down, do not scale up (for better val mAP)\n",
    "        r = min(r, 1.0)\n",
    "\n",
    "    # Compute padding\n",
    "    new_unpad = int(round(shape[1] * r)), int(round(shape[0] * r))\n",
    "    dw, dh = new_shape[1] - new_unpad[0], new_shape[0] - new_unpad[1]  # wh padding\n",
    "\n",
    "    if auto:  # minimum rectangle\n",
    "        dw, dh = np.mod(dw, stride), np.mod(dh, stride)  # wh padding\n",
    "\n",
    "    dw /= 2  # divide padding into 2 sides\n",
    "    dh /= 2\n",
    "\n",
    "    if shape[::-1] != new_unpad:  # resize\n",
    "        im = cv2.resize(im, new_unpad, interpolation=cv2.INTER_LINEAR)\n",
    "    top, bottom = int(round(dh - 0.1)), int(round(dh + 0.1))\n",
    "    left, right = int(round(dw - 0.1)), int(round(dw + 0.1))\n",
    "    im = cv2.copyMakeBorder(im, top, bottom, left, right, cv2.BORDER_CONSTANT, value=color)  # add border\n",
    "    return im, r, (dw, dh)\n",
    "\n",
    "names = ['person']\n",
    "colors = {'person' : [242, 82, 141]}\n",
    "\n",
    "outname = [i.name for i in session.get_outputs()]\n",
    "outname\n",
    "\n",
    "inname = [i.name for i in session.get_inputs()]\n",
    "inname\n",
    "\n",
    "images = [cv2.imread(file) for file in glob.glob(\"Temp/*.jpg\")]\n",
    "p_bar = tqdm(total=len(images), desc='Extracting frames')\n",
    "print(f'Finding people crowds in {len(images)} frames')\n",
    "\n",
    "number = 0\n",
    "\n",
    "for img in images:\n",
    "\timg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "\timage = img.copy()\n",
    "\timage, ratio, dwdh = letterbox(image, auto=False)\n",
    "\timage = image.transpose((2, 0, 1))\n",
    "\timage = np.expand_dims(image, 0)\n",
    "\timage = np.ascontiguousarray(image)\n",
    "\n",
    "\tim = image.astype(np.float32)\n",
    "\tim /= 255\n",
    "\tim.shape\n",
    "\n",
    "\tinp = {inname[0]:im}\n",
    "\n",
    "\toutputs = session.run(outname, inp)[0]\n",
    "\toutputs\n",
    "\n",
    "\tori_images = [img.copy()]\n",
    "\n",
    "\tfor i,(batch_id,x0,y0,x1,y1,cls_id,score) in enumerate(outputs):\n",
    "\t\timage = ori_images[int(batch_id)]\n",
    "\t\tbox = np.array([x0,y0,x1,y1])\n",
    "\t\tbox -= np.array(dwdh*2)\n",
    "\t\tbox /= ratio\n",
    "\t\tbox = box.round().astype(np.int32).tolist()\n",
    "\t\tcls_id = int(cls_id)\n",
    "\t\tif cls_id != 0 :\n",
    "\t\t\t# only keep person information\n",
    "\t\t\tcontinue\n",
    "        \n",
    "\t\tscore = round(float(score),3)\n",
    "\t\tname = names[cls_id]\n",
    "\t\tcolor = colors[name]\n",
    "\t\tname += ' '+str(score)\n",
    "\t\tcv2.rectangle(image,box[:2],box[2:],color,2)\n",
    "\t\tcv2.putText(image,name,(box[0], box[1] - 2),cv2.FONT_HERSHEY_SIMPLEX,0.75,[225, 255, 255],thickness=2) \n",
    "        \n",
    "\t\tnumber += 1\n",
    "\n",
    "\t\tif number % 50 == 0:\n",
    "\t\t\timage = cv2.resize(image, (0, 0), fx=0.25, fy=0.25)\n",
    "\t\t\tcv2.imwrite(f\"/{VIDEO_NAME}-detect{p_bar.n}.jpg\", image)\n",
    "    \n",
    "\tp_bar.update(1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Clear Caches\n",
    "\n",
    "Clear all cached frame images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete all images in the Temp folder\n",
    "import os\n",
    "\n",
    "cleared = 0\n",
    "\n",
    "for file in os.listdir(\"./Temp/\"):\n",
    "    if file.endswith(\".png\") or file.endswith(\".jpg\"):\n",
    "            cleared += 1\n",
    "            os.remove(os.path.join(\"./Temp\", file))\n",
    "            \n",
    "print(f\"\\n{cleared} images cleared.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Compress thumbnails (Optional)\n",
    "\n",
    "Run the cell below to create a ZIP of the thumbnail images and delete the thumbnail images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "zip_name = \"\"\n",
    "try:\n",
    "    if VIDEO_NAME is None:\n",
    "        zip_name = \"thumbnails\"\n",
    "except NameError:\n",
    "    zip_name = \"thumbnails\"\n",
    "else:\n",
    "    zip_name = VIDEO_NAME + \"-thumbnails\"\n",
    "\n",
    "shutil.make_archive(f\"./thumbnails/{zip_name}\", 'zip', \"./thumbnails/cache/\")\n",
    "\n",
    "cleared = 0\n",
    "\n",
    "# Delete all images in the thumbnails folder\n",
    "for file in os.listdir(\"./thumbnails/cache/\"):\n",
    "    if file.endswith(\".jpg\"):\n",
    "            cleared += 1\n",
    "            os.remove(os.path.join(\"./thumbnails/cache\", file))\n",
    "            \n",
    "print(f\"\\n{cleared} thumbnails compressed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
